Project Overview

This project involves building a Transformer-based Neural Machine Translation (NMT) system from scratch,
  training it on the Canadian Hansards dataset (English-French parallel corpus), and evaluating its
  performance using BLEU scores and translation quality analysis.

The implementation includes:
Core Transformer components (LayerNorm, Multi-Head Attention, FeedForward Layers)
Encoder-Decoder architecture (Pre/Post-Layer Normalization variants)
Decoding strategies (Greedy Search & Beam Search)
Training pipeline (Teacher Forcing, BLEU score computation)
Comparative analysis against Google Translate & fine-tuned models
